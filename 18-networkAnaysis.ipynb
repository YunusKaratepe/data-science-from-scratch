{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness Centrality\n",
    "import data_analysis_tools as da\n",
    "users = [\n",
    "{ \"id\": 0, \"name\": \"Hero\" },\n",
    "{ \"id\": 1, \"name\": \"Dunn\" },\n",
    "{ \"id\": 2, \"name\": \"Sue\" },\n",
    "{ \"id\": 3, \"name\": \"Chi\" },\n",
    "{ \"id\": 4, \"name\": \"Thor\" },\n",
    "{ \"id\": 5, \"name\": \"Clive\" },\n",
    "{ \"id\": 6, \"name\": \"Hicks\" },\n",
    "{ \"id\": 7, \"name\": \"Devin\" },\n",
    "{ \"id\": 8, \"name\": \"Kate\" },\n",
    "{ \"id\": 9, \"name\": \"Klein\" }\n",
    "]\n",
    "\n",
    "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "(4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"friends\"] = []\n",
    "\n",
    "for i, j in friendships:\n",
    "    users[i][\"friends\"].append(users[j])\n",
    "    users[j][\"friends\"].append(users[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def shortest_paths_from(from_user):\n",
    "\n",
    "    # a dictionary from \"user_id\" to all shortest paths to that user\n",
    "    shortest_paths_to = { from_user[\"id\"]: [[]] }\n",
    "\n",
    "    # a queue of (previous user, next user) that we need to check\n",
    "    # starts out with all pairs (from_user, friend_of_from_user)\n",
    "    frontier = deque((from_user, friend) for friend in from_user[\"friends\"])\n",
    "\n",
    "    # keep going until we empty the queue\n",
    "\n",
    "    while frontier:\n",
    "        prev_user, user = frontier.popleft() # remove the user who's first in the queue\n",
    "        user_id = user[\"id\"]\n",
    "\n",
    "        # because of the way we're adding to the queue\n",
    "        # necessarily we already know some shortest paths to prev_user\n",
    "        paths_to_prev_user = shortest_paths_to[prev_user[\"id\"]]\n",
    "        new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n",
    "\n",
    "        # its possible that we already know the shortest path\n",
    "        old_paths_to_user = shortest_paths_to.get(user_id, [])\n",
    "\n",
    "        # what's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_user:\n",
    "            min_path_len = len(old_paths_to_user[0])\n",
    "        else:\n",
    "            min_path_len = float('inf')\n",
    "\n",
    "        # only keep paths that aren't too long and are actually new\n",
    "        new_paths_to_user = [\n",
    "            path for path in new_paths_to_user\n",
    "            if len(path) <= min_path_len\n",
    "            and path not in old_paths_to_user\n",
    "        ]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n",
    "\n",
    "        # add never-seen neighbors to the frontier\n",
    "        frontier.extend((user, friend) for friend in user[\"friends\"]\n",
    "            if friend[\"id\"] not in shortest_paths_to\n",
    "        )\n",
    "    \n",
    "    return shortest_paths_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"shortest_paths\"] = shortest_paths_from(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[]],\n",
       " 1: [[1]],\n",
       " 2: [[2]],\n",
       " 3: [[1, 3], [2, 3]],\n",
       " 4: [[1, 3, 4], [2, 3, 4]],\n",
       " 5: [[1, 3, 4, 5], [2, 3, 4, 5]],\n",
       " 6: [[1, 3, 4, 5, 6], [2, 3, 4, 5, 6]],\n",
       " 7: [[1, 3, 4, 5, 7], [2, 3, 4, 5, 7]],\n",
       " 8: [[1, 3, 4, 5, 6, 8],\n",
       "  [2, 3, 4, 5, 6, 8],\n",
       "  [1, 3, 4, 5, 7, 8],\n",
       "  [2, 3, 4, 5, 7, 8]],\n",
       " 9: [[1, 3, 4, 5, 6, 8, 9],\n",
       "  [2, 3, 4, 5, 6, 8, 9],\n",
       "  [1, 3, 4, 5, 7, 8, 9],\n",
       "  [2, 3, 4, 5, 7, 8, 9]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[0][\"shortest_paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"betweenness_centrality\"] = 0.0\n",
    "\n",
    "for source in users:\n",
    "    source_id = source[\"id\"]\n",
    "    for target_id, paths in source[\"shortest_paths\"].items():\n",
    "        if source_id < target_id: # this is for not counting twice\n",
    "            num_paths = len(paths)\n",
    "            contrib = 1 / num_paths\n",
    "            for path in paths:\n",
    "                for id in path:\n",
    "                    if id not in [source_id, target_id]:\n",
    "                        users[id][\"betweenness_centrality\"] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 3.5\n",
      "2 3.5\n",
      "3 18.0\n",
      "4 20.0\n",
      "5 20.5\n",
      "6 6.0\n",
      "7 6.0\n",
      "8 8.5\n",
      "9 0.0\n"
     ]
    }
   ],
   "source": [
    "for user in users:\n",
    "    print(user[\"id\"], user[\"betweenness_centrality\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closeness centrality\n",
    "\n",
    "def farness(user):\n",
    "    return sum(len(paths[0]) for paths in user[\"shortest_paths\"].values())\n",
    "\n",
    "for user in users:\n",
    "    user[\"closeness_centrality\"] = 1 / farness(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.029411764705882353\n",
      "1 0.037037037037037035\n",
      "2 0.037037037037037035\n",
      "3 0.045454545454545456\n",
      "4 0.05\n",
      "5 0.05\n",
      "6 0.041666666666666664\n",
      "7 0.041666666666666664\n",
      "8 0.03571428571428571\n",
      "9 0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "for user in users:\n",
    "    print(user[\"id\"], user[\"closeness_centrality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    As we saw, computing shortest paths is kind of a pain. For this reason, betweenness and\n",
    "    closeness centrality arenâ€™t often used on large networks. The less intuitive (but generally\n",
    "    easier to compute) eigenvector centrality is more frequently used.\n",
    "\"\"\"\n",
    "from functools import partial\n",
    "# eigenvector centrality\n",
    "\n",
    "# matrix multiplication\n",
    "def matrix_product_entry(A, B, i, j):\n",
    "    return da.dot_product(A[i], da.get_column(B, j))\n",
    "\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    n1, k1 = len(A), len(A[0])\n",
    "    n2, k2 = len(B), len(B[0])\n",
    "\n",
    "    if k1 != n2:\n",
    "        raise ArithmeticError('incompatible shapes!')\n",
    "    else:\n",
    "        return da.make_matrix(n1, k2, partial(matrix_product_entry, A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 5, 4], [6, 9, 6], [9, 10, 2]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = [[1, 2],\n",
    "[2, 3],\n",
    "[3, 1]]\n",
    "\n",
    "mat2 = [[3, 3, 0],\n",
    "[0, 1, 2]]\n",
    "\n",
    "matrix_multiply(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3]]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "def vector_to_matrix(v):\n",
    "    \"\"\"converts list to nx1 matrix\"\"\"\n",
    "    return [[vi] for vi in v]\n",
    "\n",
    "def vector_from_matrix(mat):\n",
    "    \"\"\"converts nx1 matrix to list\"\"\"\n",
    "    return [row[0] for row in mat]\n",
    "\n",
    "\n",
    "mat1 = [[1, 3, 3],\n",
    "    [1, 5, -1],\n",
    "    [3, 1, 0]]\n",
    "mat = vector_to_matrix([1, 2, 3])\n",
    "vec = vector_from_matrix(mat)\n",
    "\n",
    "\n",
    "print(mat)\n",
    "print(vec)\n",
    "\n",
    "def matrix_operate(A, v):\n",
    "    v_as_matrix = vector_to_matrix(v)\n",
    "    product = matrix_multiply(A, v_as_matrix)\n",
    "    return vector_from_matrix(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eigenvector(A, tolerance=0.00001):\n",
    "\n",
    "    guess = [da.random.random() for _ in A]\n",
    "    while True:\n",
    "        result = matrix_operate(A, guess)\n",
    "        length = da.magnitude(result)\n",
    "        next_guess = da.scalar_multiply(1/length, result)\n",
    "\n",
    "        if da.euclidean(guess, next_guess) < tolerance:\n",
    "            return next_guess, length # eigenvector, eigenvalue\n",
    "            \n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4808746347547578, 0.8767893621899608], 6.645243791650158)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    note:\n",
    "    rotate = [[ 0, 1],\n",
    "            [-1, 0]]    doesn't have an eigenvector of real values\n",
    "\n",
    "    flip = [[0, 1],     eigenvector is [1, 1] but if you start with random numbers it will flip [x, y] -> [y, x] -> [x, y] and run forever.\n",
    "        [1, 0]]\n",
    "\"\"\"\n",
    "\n",
    "mat = [[3, 2],\n",
    "    [3, 5]]\n",
    "find_eigenvector(mat, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entry_fn(i, j):\n",
    "    return 1 if (i, j) in friendships or (j, i) in friendships else 0\n",
    "\n",
    "n = len(users)\n",
    "\n",
    "adjacency_matrix = da.make_matrix(n, n, entry_fn)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38578114702039273,\n",
       " 0.5147900288654446,\n",
       " 0.5147900288654446,\n",
       " 0.47331408747048337,\n",
       " 0.23360714815327532,\n",
       " 0.15014820695148395,\n",
       " 0.08355082059776549,\n",
       " 0.08355082059776549,\n",
       " 0.07284228529142327,\n",
       " 0.027292344648162888]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvector_centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directed graphs and PageRank\n",
    "\n",
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n",
    "(2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n",
    "(5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n",
    "\n",
    "for user in users:\n",
    "    user[\"endorses\"] = []\n",
    "    user[\"endorsed_by\"] = []\n",
    "\n",
    "for source_id, target_id in endorsements:\n",
    "    users[source_id][\"endorses\"].append(users[target_id])\n",
    "    users[target_id][\"endorsed_by\"].append(users[source_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endorsements_by_id = [(user[\"id\"], len(user[\"endorsed_by\"])) for user in users]\n",
    "\n",
    "sorted(endorsements_by_id, key=lambda e: e[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(users, damping=0.85, num_iters=100):\n",
    "    # initially distribute PageRank evenly\n",
    "    num_users = len(users)\n",
    "    pr = { user[\"id\"]: 1/num_users for user in users }\n",
    "\n",
    "    # this is the small fraction of PageRank\n",
    "    # that each node gets each iteration\n",
    "    base_br = (1 - damping) / num_users\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        next_pr = { user[\"id\"]: base_br for user in users }\n",
    "        \n",
    "        for user in users:\n",
    "            # distribute PageRank to outgoing links\n",
    "            links_pr = pr[user[\"id\"]] * damping\n",
    "            for endorsee in user[\"endorses\"]:\n",
    "                next_pr[endorsee[\"id\"]] += links_pr / len(user[\"endorses\"])\n",
    "        \n",
    "        pr = next_pr\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.08015082956259427),\n",
       " (1, 0.05384615384615385),\n",
       " (2, 0.05384615384615385),\n",
       " (5, 0.052941176470588235),\n",
       " (8, 0.052941176470588235),\n",
       " (0, 0.04871794871794872),\n",
       " (3, 0.04871794871794872),\n",
       " (6, 0.041176470588235294),\n",
       " (7, 0.041176470588235294),\n",
       " (9, 0.041176470588235294)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs = page_rank(users, 0.8)\n",
    "\n",
    "sorted(prs.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.04871794871794872,\n",
       " 1: 0.05384615384615385,\n",
       " 2: 0.05384615384615385,\n",
       " 3: 0.04871794871794872,\n",
       " 4: 0.08015082956259427,\n",
       " 5: 0.052941176470588235,\n",
       " 6: 0.041176470588235294,\n",
       " 7: 0.041176470588235294,\n",
       " 8: 0.052941176470588235,\n",
       " 9: 0.041176470588235294}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2675592439886072215c5492b56ef91d6259dc08377ceafc1fad216e79bf788"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}