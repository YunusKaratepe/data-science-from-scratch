{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram models\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import data_analysis_tools as da\n",
    "\n",
    "def fix_unicode(text):\n",
    "    return text.replace(u\"\\u2019\", \"'\")\n",
    "\n",
    "url = \"http://radar.oreilly.com/2010/06/what-is-data-science.html\"\n",
    "html = requests.get(url).text\n",
    "\n",
    "sp = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "content = sp.find('div', 'entry-content')\n",
    "regex = r\"[\\w']+|[\\.]\"\n",
    "\n",
    "document = []\n",
    "\n",
    "for p in content('p'):\n",
    "    words = re.findall(regex, fix_unicode(p.text))\n",
    "    document.extend(words)\n",
    "\n",
    "# continue on pg 338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'your']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this means 'data' and 'you' are the 2 words which follows 'government' in this article.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word pairs\n",
    "from collections import defaultdict\n",
    "bigrams = zip(document, document[1:])\n",
    "transitions = defaultdict(list)\n",
    "\n",
    "for prev, current in bigrams:\n",
    "    transitions[prev].append(current)\n",
    "\n",
    "print(transitions['government'])\n",
    "\"\"\"this means 'data' and 'you' are the 2 words which follows 'government' in this article.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Random Bullshit Sentences ->\n",
      "\n",
      "   - They group together at events that knows how to a number of this post I haven't stressed traditional statistics to understand the next generation of cancer throughout a solution to work .\n",
      "\n",
      "   - Describing the application .\n",
      "\n",
      "   - Visualization is that can think about statistics is that sounds like an even an unknown album titles .\n",
      "\n",
      "   - Almost any data science data but Hadoop or product cycles closer interaction between developers of these databases appear .\n",
      "\n",
      "   - You don't yet know what you need some point it's possible .\n"
     ]
    }
   ],
   "source": [
    "# generating sentences\n",
    "def generate_using_bigrams(transitions):\n",
    "    current = \".\" # this means the next word will start a sentence\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]\n",
    "        current = da.random.sample(next_word_candidates)\n",
    "        result.append(current)\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)\n",
    "\n",
    "print('5 Random Bullshit Sentences ->')\n",
    "print('\\n   -', generate_using_bigrams(transitions))\n",
    "print('\\n   -', generate_using_bigrams(transitions))\n",
    "print('\\n   -', generate_using_bigrams(transitions))\n",
    "print('\\n   -', generate_using_bigrams(transitions))\n",
    "print('\\n   -', generate_using_bigrams(transitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = zip(document, document[1:], document[2:])\n",
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "\n",
    "for prev, current, next in trigrams:\n",
    "    if prev == \".\":\n",
    "        starts.append(current)\n",
    "    trigram_transitions[(prev, current)].append(next)\n",
    "\n",
    "trigram_transitions[('successful', 'businesses')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Random Sentences ->\n",
      "\n",
      "   - In addition to looking at profiles LinkedIn's data scientists are involved with gathering data massaging it into a large collection of public photos from Twitter you can start thinking about the difference between 5 .\n",
      "\n",
      "   - It's the kind of question we now ask routinely .\n",
      "\n",
      "   - Physicists have a strong mathematical background computing skills and come from a number of other databases and data conditioning you have 1 010 or 1 012 Twitter followers Precision has an allure but in most data analysis project is data conditioning if you need to create animations that show how things change over time .\n",
      "\n",
      "   - 2 Information Platforms as Dataspaces by Jeff Hammerbacher 2 hackingdata we're trying to build interesting products from it to extract value from it .\n",
      "\n",
      "   - We are seeing more data as it arrives and delivers intermediate results are then distributed across many processors the intermediate results in near real time MapReduce to get presentable results .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'They seem much more realistic compare to biagrams tho.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_using_trigrams(transitions, starts):\n",
    "\n",
    "    current = da.random.sample(starts)\n",
    "    prev = \".\"\n",
    "    result = [current]\n",
    "\n",
    "    while True:\n",
    "        next_word_candidates = transitions[(prev, current)]\n",
    "        next_word = da.random.sample(next_word_candidates)\n",
    "        \n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)\n",
    "\n",
    "print('5 Random Sentences ->')\n",
    "print('\\n   -', generate_using_trigrams(trigram_transitions, starts))\n",
    "print('\\n   -', generate_using_trigrams(trigram_transitions, starts))\n",
    "print('\\n   -', generate_using_trigrams(trigram_transitions, starts))\n",
    "print('\\n   -', generate_using_trigrams(trigram_transitions, starts))\n",
    "print('\\n   -', generate_using_trigrams(trigram_transitions, starts))\n",
    "\n",
    "\"\"\"They seem much more realistic compare to biagrams tho.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammars pg 340"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2675592439886072215c5492b56ef91d6259dc08377ceafc1fad216e79bf788"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}